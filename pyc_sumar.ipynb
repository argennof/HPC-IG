{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argennof/HPC-IG/blob/main/pyc_sumar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHlaJ6twF7AY"
      },
      "outputs": [],
      "source": [
        "# EJERCICIOS:\n",
        "\n",
        "#  Implementa un programa que sume dos vectores/matrices:\n",
        "#\n",
        "#  1) Suma de dos vectores de 20 elementos\n",
        "#  2) Suma de dos vectores de 1500 elementos\n",
        "#  3) Suma de dos matrices de 8x10 elementos\n",
        "#  4) Suma de dos matrices de 100x150 elementos\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 1\n",
        "\n",
        "# Suma: 1D / 1 Block\n",
        "#  c = a + b\n",
        "#  Elementos: 20\n",
        "\n",
        "\n",
        "# 1D / 1 Block\n",
        "#  doblar vector\n",
        "#   Implementaci√≥n con SourceModule de duplicar elementos de un vector.\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "import pycuda.driver as drv\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Parametros de configuracion:\n",
        "    drv.init()\n",
        "    dev = drv.Device(0) # Device 0\n",
        "    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n",
        "    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n",
        "\n",
        "    # 1. Definir kenel\n",
        "    mod = SourceModule (\"\"\"\n",
        "    __global__ void sumar_vector(float *a, float *b, float *c, int size) {\n",
        "        int i = threadIdx.x + (blockDim.x, blockIdx.x);\n",
        "        if (i < size) {\n",
        "            c[i] = a[i] + b[i];\n",
        "        }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Definiendo los vectores y Reserva memoria en GPU:\n",
        "    SIZE = 20\n",
        "    a = np.arange(SIZE, dtype=np.float32)\n",
        "    b = np.arange(SIZE, dtype=np.float32)\n",
        "    c = np.empty_like(a)  \n",
        "\n",
        "\n",
        "    a_gpu = drv.mem_alloc(a.nbytes)\n",
        "    b_gpu = drv.mem_alloc(b.nbytes)\n",
        "    c_gpu = drv.mem_alloc(c.nbytes)\n",
        "\n",
        "    # 3. Transferir datos host->GPU\n",
        "    drv.memcpy_htod(a_gpu, a)\n",
        "    drv.memcpy_htod(b_gpu, b)\n",
        "\n",
        " \n",
        "\n",
        "    # 4. Invoca kernel\n",
        "    grid_x= math.ceil(SIZE / max_thr_per_blk)\n",
        "\n",
        "    sumar = mod.get_function(\"sumar_vector\")\n",
        "    sumar(a_gpu,a_gpu,c_gpu, np.intc(SIZE), block = (SIZE, 1, 1), \n",
        "                  grid  = (  grid_x, 1, 1) )\n",
        "\n",
        "    # 5. Transferir datos GPU->host\n",
        "    #c = resultado de la suma\n",
        "    drv.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "    print(\"Vector:\", a)\n",
        "    print(\"Vector:\", b)\n",
        "    print(\"Vector Suma:\", c)"
      ],
      "metadata": {
        "id": "f5B2298MjMoj",
        "outputId": "b63f967c-0ac4-4ead-bb2b-efd4d60e8376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2022.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2022.1.12)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (2.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.1)\n",
            "MAX_THREADS_PER_BLOCK:  1024\n",
            "Vector: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19.]\n",
            "Vector: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19.]\n",
            "Vector Suma: [ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
            " 36. 38.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 2\n",
        "\n",
        "# Suma: 1D / N Blocks\n",
        "#  c = a + b\n",
        "#  Elementos: 1500\n",
        "\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "import pycuda.driver as drv\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Parametros de configuracion:\n",
        "    drv.init()\n",
        "    dev = drv.Device(0) # Device 0\n",
        "    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n",
        "    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n",
        "\n",
        "    # 1. Definir kenel\n",
        "\n",
        "    # 2. Reserva memoria en GPU:\n",
        "\n",
        "    # 3. Transferir datos host->GPU\n",
        "\n",
        "    # 4. Invoca kernel\n",
        "\n",
        "    # 5. Transferir datos GPU->host\n"
      ],
      "metadata": {
        "id": "zczOSzQhlByw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 3\n",
        "\n",
        "# Suma: 2D / 1 Block\n",
        "#  C = A + B\n",
        "#  Elementos: 8 x 10\n",
        "\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "import pycuda.driver as drv\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Parametros de configuracion:\n",
        "    drv.init()\n",
        "    dev = drv.Device(0) # Device 0\n",
        "    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n",
        "    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n",
        "\n",
        "\n",
        "    # 1. Definir kenel\n",
        "\n",
        "    # 2. Reserva memoria en GPU:\n",
        "\n",
        "    # 3. Transferir datos host->GPU\n",
        "\n",
        "    # 4. Invoca kernel\n",
        "\n",
        "    # 5. Transferir datos GPU->host\n"
      ],
      "metadata": {
        "id": "ZNR27j9LmBH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJERCICIO 4\n",
        "\n",
        "# Suma: 2D / N Blocks\n",
        "#  C = A + B\n",
        "#  Elementos: 100 x 150\n",
        "\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "import pycuda.driver as drv\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Parametros de configuracion:\n",
        "    drv.init()\n",
        "    dev = drv.Device(0) # Device 0\n",
        "    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n",
        "    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n",
        "\n",
        "\n",
        "    # 1. Definir kenel\n",
        "\n",
        "    # 2. Reserva memoria en GPU:\n",
        "\n",
        "    # 3. Transferir datos host->GPU\n",
        "\n",
        "    # 4. Invoca kernel\n",
        "\n",
        "    # 5. Transferir datos GPU->host\n"
      ],
      "metadata": {
        "id": "uXppgVYtrO27"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pyc_sumar.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}